[Unit]
Description=llama.cpp server (Nemotron-3-Nano)
After=network-online.target
Wants=network-online.target

[Service]
Type=simple
WorkingDirectory=%h/llama.cpp

# Pin to A720 cores only
CPUAffinity=0 1 6 7 8 9 10 11

# Keep generation on 8 threads (your bench says this is best)
ExecStart=%h/llama.cpp/build/bin/llama-server \
  --model %h/models/Nemotron-3-Nano-30B-A3B-Q4_0.gguf \
  --alias nemotron-3-nano-30b-a3b \
  --ctx-size 8192 \
  --threads 8 \
  --threads-batch 8 \
  --batch-size 512 \
  --ubatch-size 128 \
  --parallel 1 \
  --host 0.0.0.0 \
  --port 8765
  --mmap
  --no-mlock

Restart=on-failure
RestartSec=2
Nice=-5

[Install]
WantedBy=default.target

